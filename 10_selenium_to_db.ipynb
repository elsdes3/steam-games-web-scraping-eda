{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca7d57b-f12b-4047-96b8-7a392e59a49c",
   "metadata": {},
   "source": [
    "# Create MySQL Database for Data scraped with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c6f8f-88a5-427f-94d4-aa4cb473624e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891127c9-dfb7-48a5-a937-58f2a57d3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import requests\n",
    "from prefect import Flow, task, unmapped\n",
    "from prefect.tasks.mysql import MySQLFetch, MySQLExecute\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5583cf-8011-46ea-a7aa-54b3892fa446",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a href=\"table-of-contents\"></a>\n",
    "\n",
    "## [Table of Contents](#table-of-contents)\n",
    "0. [About](#about)\n",
    "1. [User Inputs](#user-inputs)\n",
    "2. [MySQL server and database pre-requisites](#mysql-server-and-database-pre-requisites)\n",
    "   - 2.1. [Download SSL Certificates](#download-ssl-certificates)\n",
    "   - 2.2. [Specify Database Connection string](#specify-database-connection-string)\n",
    "3. [Perform Administrative Actions on the Server](#perform-administrative-actions-on-the-server)\n",
    "4. [Create and Populate Tables](#create-and-populate-tables)\n",
    "   - 4.1. [Load Data with Python to decide on MySQL datatypes](#load-data-with-python-to-decide-on-mysql-datatypes)\n",
    "   - 4.2. [Specify MySQL commands to create table and alter datatypes](#specify-mysql-commands-to-create-table-and-alter-datatypes)\n",
    "   - 4.3. [Create table and append `DataFrame` to table](#create-table-and-append-`dataframe`-to-table)\n",
    "   - 4.4. [Change column datatypes](#change-column-datatypes)\n",
    "5. [Drop Tables](#drop-tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5052b-f652-4f8a-b8f2-f5a6fdf74304",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "\n",
    "## 0. [About](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a163db-b6ba-4281-b350-7722e74a9c56",
   "metadata": {},
   "source": [
    "In this notebook, we'll download the scraped search results and listings, scraped using Selenium, from cloud storage and clean both datasets. We'll then merge the cleaned datasets and append this clean version to a MySQL database table.\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "The intended workflow that these actions will comprise is the following\n",
    "- retrieve raw scraped data (search results and listings) from cloud storage\n",
    "- process (clean) the raw data\n",
    "- append the clean data to a MySQL database\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "The above workflow has the following assumptions\n",
    "- data was retrieved by web-scraping with Selenium (eg. using `2_*.ipynb`)\n",
    "  - scraped data is stored in files with names `p*_l*__*.ipynb` (listings) and `search_results_*.ipynb` (search results) in `data/raw/selenium`\n",
    "- raw scraped data is uploaded (from `data/raw/selenium`) to cloud storage (eg. using `8_*.ipynb`)\n",
    "\n",
    "In order to [orchestrate](https://www.qubole.com/blog/apache-airflow-tutorial-etl-elt-workflow-orchestration-made-easy/) this process of downloading (Extract), cleaning (Transform) and loading data into a database (Load), a [workflow management](https://fivetran.com/blog/data-orchestration-explained-no-diy) tool (Prefect) will be used. This is optional and was not a requirement, but has been used here as was done in the notebooks to upload (`8_*.ipynb`) and download (`9_*.ipynb`) data.\n",
    "\n",
    "This notebook will use Prefect to perform each of the E-T-L steps of the workflow described above.\n",
    "\n",
    "**Notes**\n",
    "1. The MySQL database used here will be configured to [use SSL connections between the server and client](https://www.datasunrise.com/blog/professional-info/mitm-sql_server-protection/). If so, the SSL connection configuration might [use](https://community.bitnami.com/t/how-can-i-connect-to-a-mysql-database-that-requires-ssl/56589) ([example manual setup](https://www.howtoforge.com/tutorial/how-to-enable-ssl-and-remote-connections-for-mysql-on-centos-7/)) a [SSL certificate from DigiCert](https://www.digicert.com/kb/digicert-root-certificates.htm).\n",
    "\n",
    "**Requirements**\n",
    "1. As mentioned in the [`README.md`](https://github.com/elsdes3/steam-games-web-scraping-eda/blob/master/README.md), the following environment variables must be defined in the calling shell before running this notebook\n",
    "   ```bash\n",
    "   export MYSQL_ADMIN_USER_NAME=<credential-here>\n",
    "   export MYSQL_ADMIN_USER_PWD=<credential-here>\n",
    "   export MYSQL_NON_ADMIN_USER_NAME=<credential-here>\n",
    "   export MYSQL_NON_ADMIN_USER_PWD=<credential-here>\n",
    "   export MYSQL_HOST=localhost\n",
    "   export MYSQL_PORT=3306\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a858c-ef91-4605-99d9-229b5ebcfece",
   "metadata": {},
   "source": [
    "<a id=\"user-inputs\"></a>\n",
    "\n",
    "## 1. [User Inputs](#user-inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef4512-bfa2-41f1-9d24-f3131b027176",
   "metadata": {},
   "source": [
    "Define variables that can be changed when running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054f0f1-7ea8-410e-bfd4-7a04e9e56e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT_DIR = os.getcwd()\n",
    "admin_user = os.getenv(\"MYSQL_ADMIN_USER_NAME\")\n",
    "non_admin_user = os.getenv(\"MYSQL_NON_ADMIN_USER_NAME\")\n",
    "host = os.getenv(\"MYSQL_HOST\")\n",
    "port = int(os.getenv(\"MYSQL_PORT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc56b21-1c8e-4ac7-a720-2c19375318be",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "database_name = \"mydbdemo\"\n",
    "\n",
    "ssl_cert_url = \"https://www.digicert.com/CACerts/BaltimoreCyberTrustRoot.crt.pem\"\n",
    "\n",
    "# for creating database, set \"no\" to create database; otherwise, set \"yes\"\n",
    "is_database_exists = False\n",
    "\n",
    "# for creating user, set \"no\" to create a user; otherwise, set \"yes\"\n",
    "is_user_exists = False\n",
    "\n",
    "# name of database table to hold scraped data\n",
    "table_name = \"listings\"\n",
    "\n",
    "# whether to delete database table\n",
    "drop_table = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1b37d-0778-4ad6-aa00-c07751ecaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data/raw\n",
    "data_dir = os.path.join(PROJ_ROOT_DIR, \"data\")\n",
    "raw_data_dir = os.path.join(data_dir, \"raw\")\n",
    "\n",
    "# Path to data/raw/selenium\n",
    "selenium_files_dir = os.path.join(raw_data_dir, \"selenium\")\n",
    "\n",
    "# List of listings CSV files created using selenium\n",
    "fpaths_selenium = glob(os.path.join(selenium_files_dir, \"p*_*.csv\"))\n",
    "\n",
    "# List of search results files created by Selenium\n",
    "selenium_search_results_pages = glob(\n",
    "    os.path.join(selenium_files_dir, \"search_results_page_*_*.parquet.gzip\")\n",
    ")\n",
    "\n",
    "# Path to locally downloaded SSL certificate\n",
    "ssl_cert_path = os.path.join(raw_data_dir, \"BaltimoreCyberTrustRoot.crt.pem\")\n",
    "\n",
    "# Non-Admin user name without @<host-name>\n",
    "non_admin_user_name = (\n",
    "    non_admin_user.split(\"@\")[0] if host != \"localhost\" else non_admin_user\n",
    ")\n",
    "\n",
    "# Admin and non-admin user passwords\n",
    "admin_user_pwd = os.getenv(\"MYSQL_ADMIN_USER_PWD\")\n",
    "non_admin_user_pwd = os.getenv(\"MYSQL_NON_ADMIN_USER_PWD\")\n",
    "\n",
    "# Connection dictionary for MySQL-Python client\n",
    "conn_dict = dict(\n",
    "    db_name=database_name,\n",
    "    user=non_admin_user,\n",
    "    password=non_admin_user_pwd,\n",
    "    host=host,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a52d718-0cc8-4006-91c8-fb1a09816ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_df(df, col_dtype_to_show):\n",
    "    if col_dtype_to_show == \"object\":\n",
    "        # Get string dtype columns\n",
    "        cols_to_show = list(df.select_dtypes(\"object\"))\n",
    "        # Get max length of string\n",
    "        df_max = (\n",
    "            df[cols_to_show]\n",
    "            .astype(str)\n",
    "            .apply(lambda x: x.str.len().max(), axis=0)\n",
    "            .rename(\"max_length\")\n",
    "            .to_frame()\n",
    "        )\n",
    "    else:\n",
    "        # Get non-string (numerical) dtype columns\n",
    "        cols_to_show = list(set(list(df)) - set(list(df.select_dtypes(\"object\"))))\n",
    "        # Get max numerical value\n",
    "        df_max = df[cols_to_show].max().rename(\"max_value\").to_frame()\n",
    "    display(\n",
    "        df_max.merge(\n",
    "            df[cols_to_show].dtypes.rename(\"dtype\").to_frame(),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .merge(\n",
    "            df[cols_to_show].isna().sum().rename(\"num_missing\").to_frame(),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .merge(\n",
    "            df[cols_to_show]\n",
    "            .dropna(how=\"any\")\n",
    "            .sample(1)\n",
    "            .squeeze()\n",
    "            .rename(\"single_non_nan_value\")\n",
    "            .to_frame(),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def show_sql_df(query, cursor, cnx=None, table_output=False):\n",
    "    cursor.execute(query)\n",
    "    if cnx:\n",
    "        cnx.commit()\n",
    "    if table_output:\n",
    "        colnames = [cdesc[0] for cdesc in cursor.description]\n",
    "        cur_fetched = cursor.fetchall()\n",
    "        if cur_fetched:\n",
    "            df_oper_out = pd.DataFrame.from_records(cur_fetched, columns=colnames)\n",
    "            display(df_oper_out)\n",
    "        else:\n",
    "            df_oper_out = pd.DataFrame()\n",
    "        return df_oper_out\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def sqlalchemy_show_query_df(\n",
    "    query, db_connection, use_exception_handling=False, show_output=False\n",
    "):\n",
    "    df = pd.DataFrame()\n",
    "    if use_exception_handling:\n",
    "        try:\n",
    "            df = pd.read_sql(query, con=db_connection)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    else:\n",
    "        df = pd.read_sql(query, con=db_connection)\n",
    "    if not df.empty and show_output:\n",
    "        display(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4726c-3c37-4b83-a0b6-83a1f790bda2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_concatenate_listings_search_results(\n",
    "    listing_filepaths, selenium_search_results_pages\n",
    "):\n",
    "    \"\"\"Clean and merge listings and search results datasets.\"\"\"\n",
    "    # Process Listings files\n",
    "    df_listings = (\n",
    "        pd.concat(\n",
    "            [pd.read_csv(f) for f in listing_filepaths],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        .dropna(subset=[\"Title\"])\n",
    "        .sort_values(by=[\"page_num\", \"listing_num\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Process Search Results files\n",
    "    df_search_results = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.read_parquet(\n",
    "                    selenium_search_results_page,\n",
    "                    engine=\"auto\",\n",
    "                )\n",
    "                for selenium_search_results_page in selenium_search_results_pages\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        .astype({\"page\": int})\n",
    "        .dropna(subset=[\"title\"])\n",
    "        .sort_values(by=[\"page\", \"listing_counter\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Drop duplicated search results\n",
    "    # - these appeared on a multiple page numbers when the Selenium\n",
    "    #   webdriver queried the Steam store search\n",
    "    df_search_results = df_search_results.drop_duplicates(\n",
    "        subset=[\"title\", \"url\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Merge listings with search results\n",
    "    dfm = df_search_results.merge(\n",
    "        df_listings,\n",
    "        left_on=[\"title\"],\n",
    "        right_on=[\"Title\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Replace blank strings in date tolumns by NaN\n",
    "    dfm[\"Early Access Release Date\"] = dfm[\"Early Access Release Date\"].replace(\n",
    "        \"\", None\n",
    "    )\n",
    "    dfm[\"Release Date\"] = dfm[\"Release Date\"].replace(\"\", None)\n",
    "    dfm[\"release_date\"] = dfm[\"release_date\"].replace(\"\", None)\n",
    "\n",
    "    # Add suffix to the column name for attributes that were scraped from both the\n",
    "    # search results and the listings (add suffix to column scraped from the listings)\n",
    "    multi_scraped_cols = [\"Title\", \"Release Date\", \"platforms\"]\n",
    "    dfm = dfm.rename(columns={c: c + \"_listings\" for c in multi_scraped_cols})\n",
    "\n",
    "    # Clean column names\n",
    "    dfm.columns = dfm.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "    # Clean string columns\n",
    "    dfm[\"pct_overall_threshold\"] = dfm[\"pct_overall_threshold\"].str.split(\n",
    "        \"<br>\", expand=True\n",
    "    )[0]\n",
    "    dfm[\"pct_overall_threshold_lang\"] = dfm[\"pct_overall_threshold_lang\"].str.split(\n",
    "        \"<br>\", expand=True\n",
    "    )[0]\n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b166f-68c6-453e-9eb0-f653bb91e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def run_sql_query(conn_dict, query, ssl_cert_path):\n",
    "    sql_execute = MySQLExecute(**conn_dict)\n",
    "    query_nrows_affected = sql_execute.run(\n",
    "        query=query,\n",
    "        ssl=dict(MYSQL_OPT_SSL_CAPATH=ssl_cert_path),\n",
    "    )\n",
    "    return query_nrows_affected\n",
    "\n",
    "\n",
    "@task\n",
    "def extract_transform(listing_filepaths, selenium_search_results_pages):\n",
    "    return load_concatenate_listings_search_results(\n",
    "        listing_filepaths, selenium_search_results_pages\n",
    "    )\n",
    "\n",
    "\n",
    "@task\n",
    "def load_my_data(df, table_name, db_connection):\n",
    "    df.to_sql(table_name, con=db_connection, index=False, if_exists=\"append\")\n",
    "\n",
    "\n",
    "@task\n",
    "def query_database(conn_dict, query, table_name, ssl_cert_path):\n",
    "    sql_fetch = MySQLFetch(**conn_dict)\n",
    "    query_result = sql_fetch.run(\n",
    "        query=query,\n",
    "        ssl=dict(MYSQL_OPT_SSL_CAPATH=ssl_cert_path),\n",
    "        fetch=\"all\",\n",
    "    )\n",
    "    colnames_tuples = sql_fetch.run(\n",
    "        query=f\"SHOW COLUMNS FROM {table_name}\",\n",
    "        ssl=dict(MYSQL_OPT_SSL_CAPATH=ssl_cert_path),\n",
    "        fetch=\"all\",\n",
    "    )\n",
    "    # print(colnames_tuples)\n",
    "    colnames = [colnames_tuple[0] for colnames_tuple in colnames_tuples]\n",
    "    df_query = pd.DataFrame.from_records(query_result, columns=colnames)\n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa9445-ecbc-4b11-a773-6a5571dcd8f8",
   "metadata": {},
   "source": [
    "<a id=\"mysql-server-and-database-pre-requisites\"></a>\n",
    "\n",
    "## 2. [MySQL server and database pre-requisites](#mysql-server-and-database-pre-requisites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc86558-5f63-40f0-83fc-cd213e1be6a5",
   "metadata": {},
   "source": [
    "<a id=\"download-ssl-certificates\"></a>\n",
    "\n",
    "### 2.1. [Download SSL Certificates](#download-ssl-certificates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7724ec-39a8-45a8-bbcc-5e4dae8fa0fc",
   "metadata": {},
   "source": [
    "Since [SSL was enforced on the MySQL server VM](https://docs.microsoft.com/en-us/azure/mysql/howto-configure-ssl#using-azure-cli), follow [instructions on Azure documentation](https://docs.microsoft.com/en-us/azure/mysql/howto-configure-ssl#step-1-obtain-ssl-certificate) to download the SSL certificate required for connecting with\n",
    "- `sqlalchemy`\n",
    "  - via `create_engine`\n",
    "  - docs ([1](https://docs.sqlalchemy.org/en/14/core/engines.html), [2](https://docs.sqlalchemy.org/en/14/dialects/mysql.html#ssl-connections))\n",
    "    - when querying the database\n",
    "- `mysql-connector-python`\n",
    "  - via the `ssl_ca` keyword in `.connect()`\n",
    "  - docs ([1](https://docs.microsoft.com/en-us/azure/mysql/howto-configure-ssl#python-mysqlconnector-python), [2](https://dev.mysql.com/doc/connector-python/en/connector-python-example-connecting.html), [3](https://dev.mysql.com/doc/connector-python/en/connector-python-connectargs.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db1d68-6e22-4752-8e95-380d57fda488",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ssl_cert_path):\n",
    "    response = requests.get(ssl_cert_url)\n",
    "    with open(ssl_cert_path, \"wb\") as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beeb060-3550-4286-a5c5-cfc15f589168",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ssl_cert_path)\n",
    "ssl_args = {\"ssl_ca\": ssl_cert_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0918b28-21de-4ed1-b78f-059496c3ecf3",
   "metadata": {},
   "source": [
    "<a id=\"specify-database-connection-string\"></a>\n",
    "\n",
    "### 2.2. [Specify Database Connection string](#specify-database-connection-string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e420023-403c-46c7-8608-86ef35a2baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection_str = (\n",
    "    f\"mysql+mysqlconnector://{non_admin_user}:{non_admin_user_pwd}@\"\n",
    "    f\"{host}:{port}/{database_name}\"\n",
    ")\n",
    "db_connection = create_engine(db_connection_str, connect_args=ssl_args)\n",
    "print(db_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c9ba9-2a2f-4426-a2bf-ba602adf8c9d",
   "metadata": {},
   "source": [
    "This will be used by SQLAlchemy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb10ec-1d4d-4dec-81d8-88f83c9171f5",
   "metadata": {},
   "source": [
    "<a id=\"perform-administrative-actions-on-the-server\"></a>\n",
    "\n",
    "## 3. [Perform Administrative Actions on the Server](#perform-administrative-actions-on-the-server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a89b9ff-ee79-4aeb-bfa5-43f51c01ccfd",
   "metadata": {},
   "source": [
    "Perform one-time administrative actions on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72fe37-3c1c-46f1-a013-88044ee6271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=host,\n",
    "    user=admin_user,\n",
    "    password=admin_user_pwd,\n",
    "    ssl_ca=ssl_cert_path,\n",
    "    port=port,\n",
    ")\n",
    "cur = mydb.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38a8f1-e0ce-4e84-858b-5e09a85a98c6",
   "metadata": {},
   "source": [
    "Create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e60c00-82cb-4721-a819-50a60bb489d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if not is_database_exists:\n",
    "    query = f\"CREATE DATABASE IF NOT EXISTS {database_name}\"\n",
    "    show_sql_df(query, cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac751787-0732-4c87-abf0-4a0f2a57f2b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Create a user and grant the user all privileges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de12071-95df-4fc8-b002-525c62300c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if not is_user_exists:\n",
    "    for query in [\n",
    "        f\"CREATE USER '{non_admin_user_name}'@'%' IDENTIFIED BY '{non_admin_user_pwd}'\",\n",
    "        f\"GRANT ALL PRIVILEGES ON {database_name} . * TO '{non_admin_user_name}'@'%'\",\n",
    "        \"FLUSH PRIVILEGES\",\n",
    "    ]:\n",
    "        show_sql_df(query, cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb16fd2-3ddd-4651-9ed3-6eafbc090e5e",
   "metadata": {},
   "source": [
    "Show whether the MySQL server is configured to use a SSL connection between the server and client application ([1](https://stackoverflow.com/a/37319152/4057186), [2](https://dba.stackexchange.com/a/40176/177332))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12459072-ff79-4507-a6f4-78c389a1ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = \"SHOW STATUS LIKE 'Ssl_cipher'\"\n",
    "_ = show_sql_df(query, cur, table_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d95e30-5f09-4a89-b179-5be1e4e2fe0e",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The `Value` column of the output will be\n",
    "   - empty, if SSL is not configured on the MySQL server\n",
    "   - populated, if the MySQL server enforces a SSL connection to the client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9a6bb-c4d9-43de-a490-8ae665ea15fb",
   "metadata": {},
   "source": [
    "Show available databases after creating the `airbnb` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f158f-3cf7-4618-ab56-9f6c751caa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = \"SHOW DATABASES\"\n",
    "_ = show_sql_df(query, cur, table_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f7ea6-51c4-454d-85bf-36d8051d3a53",
   "metadata": {},
   "source": [
    "Show the updated user names and selected privileges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee64e30-70aa-46b7-9eef-b56bb4854133",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = \"SELECT User, Update_priv, Insert_priv, Alter_priv, Grant_priv, Drop_priv FROM mysql.user\"\n",
    "_ = show_sql_df(query, cur, table_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13df88-8289-4f68-8526-ff545bca6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.close()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b299c194-a182-4cf5-aabf-25c2400d48f4",
   "metadata": {},
   "source": [
    "<a id=\"create-and-populate-tables\"></a>\n",
    "\n",
    "## 4. [Create and Populate Tables](#create-and-populate-tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121879d0-d52e-450f-8e90-ebbb359e7beb",
   "metadata": {},
   "source": [
    "<a id=\"load-data-with-python-to-decide-on-mysql-datatypes\"></a>\n",
    "\n",
    "### 4.1. [Load Data with Python to decide on MySQL datatypes](#load-data-with-python-to-decide-on-mysql-datatypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa82c3-2d65-4624-bc04-6166d1f8e4ca",
   "metadata": {},
   "source": [
    "Load the data with `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8def9b0-8eab-438c-b98c-423a23bd7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = load_concatenate_listings_search_results(\n",
    "    fpaths_selenium, selenium_search_results_pages\n",
    ")\n",
    "display(df.head(1).append(df.tail(1)))\n",
    "display(df[[\"platform_names\", \"platforms_listings\", \"languages\", \"num_languages\"]].sample(5))\n",
    "display(df.dtypes.rename(\"dtype\").to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce425e4f-0f5a-445e-865e-30138345c980",
   "metadata": {},
   "source": [
    "We'll now show the datatype, maximum length (number of characters) and a random non-missing value from the columns that are of string datatype (upper) and non-strings (floats or integers, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19557270-37ff-4035-ac5f-c18615b9c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df, \"object\")\n",
    "summarize_df(df, \"numerical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a43e453-74f3-4085-b2c5-c4084348aa21",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. There are a number of numerical columns that `pandas` has as `float`s but that should be integers. These are the identification columns, such as `page`, `page_num`, `listing_num`, etc. Of these, `page` and `listing_num` are not missing values and they shouldn't be missing any. `page_num` is only missing since some listings that appeared in the search results were not scraped, as has been discussed in earlier notebooks. There are also the number of positive (`review_type_positive`) and negative (`review_type_negative`) reviews that need to be integers. The same is true for `review_language_mine` (the number of listing reviews in the selected language), `num_languages` (the number of languages supported by the listing) and `num_steam_achievements`(the number of Steam achievements, which will be an integer with a value of 0 or higher). All these columns should be integers but, due to the presence of missing values in `pandas`, are floats in the `DataFrame`. The `int` dtype in `MySQL` supports the `NULL` values. So, we need to, for example, convert all these columns into `int`s after loading the data.\n",
    "\n",
    "   Since the raw data is being loaded into a `DataFrame`, before inserting it in to the MySQL table, the `DataFrame` datatype of these `int` columns will be `float` since they have missing values. When this `DataFrame` is then added data to the database table, the data in that table's corresponding columns will also be `float`s (since a `DataFrame` can't have an `int` with missing values in a column). So, we'll have to populate the table and then use a MySQL `ALTER TABLE` command to change the columns' datatype to `int`.\n",
    "\n",
    "   Since the database will only be created and populated after all data has been scraped, a single `ALTER TABLE` command (on the populated table) can be run. This approach will be used here. Alternatively, if we wanted to iteratively append new data to the table (immediately after scraping), we could leave these columns as a MySQL `float`, append new rows (with these columns again appearing as `float`s) and only run the `ALTER TABLE` command to convert them to a MySQL `int` after all the scraping is done and no further data is to be added to the table.\n",
    "2. For the string columns, we can use the above displayed output (the upper of the two) to pick the MySQL datatype for those columns of the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1617d2-9dcb-4b07-afce-36078829f749",
   "metadata": {},
   "source": [
    "<a id=\"specify-mysql-commands-to-create-table-and-alter-datatypes\"></a>\n",
    "\n",
    "### 4.2. [Specify MySQL commands to create table and alter datatypes](#specify-mysql-commands-to-create-table-and-alter-datatypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a431504-6b9b-45d2-a0c2-23f38b67da1e",
   "metadata": {},
   "source": [
    "Based on the previous sub-section, we'll create a dictionary of non-string columns with their new datatypes (integer) and, use these to create a list of `ALTER TABLE` commands to modify the column datatypes after inserting data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a647f-b86f-4b83-a85a-842404b6753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dtypes_to_change_dict = {\n",
    "    \"num_languages\": \"int\",\n",
    "    \"page_num\": \"int\",\n",
    "    \"listing_num\": \"int\",\n",
    "    \"num_steam_achievements\": \"int\",\n",
    "    \"review_type_positive\": \"int\",\n",
    "    \"review_type_negative\": \"int\",\n",
    "    \"review_language_mine\": \"int\",\n",
    "}\n",
    "cn_queries = [\n",
    "    f\"\"\"ALTER TABLE {table_name} MODIFY {col_name} {new_dtype}\"\"\"\n",
    "    for col_name, new_dtype in col_dtypes_to_change_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9b8fe-8eb6-4d7c-9fe2-1a53202d1552",
   "metadata": {},
   "source": [
    "We'll now define the MySQL `CREATE TABLE` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcee04-5212-47c3-aca5-d3557326a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = f\"\"\"\n",
    "                     CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                         listing_id INT NOT NULL AUTO_INCREMENT,\n",
    "                         page int,\n",
    "                         listing_counter int,\n",
    "                         title text COLLATE utf8mb4_unicode_ci,\n",
    "                         url blob,\n",
    "                         platform_names varchar(50),\n",
    "                         release_date varchar(20),\n",
    "                         discount_pct varchar(10),\n",
    "                         original_price varchar(50),\n",
    "                         discount_price varchar(50),\n",
    "                         review_type_all float,\n",
    "                         overall_review_rating varchar(30),\n",
    "                         pct_overall float,\n",
    "                         pct_overall_threshold varchar(20),\n",
    "                         pct_overall_lang float,\n",
    "                         pct_overall_threshold_lang varchar(20),\n",
    "                         platforms_listings varchar(25),\n",
    "                         user_defined_tags text,\n",
    "                         num_steam_achievements float,\n",
    "                         drm text COLLATE utf8mb4_unicode_ci,\n",
    "                         rating varchar(10),\n",
    "                         rating_descriptors varchar(150),\n",
    "                         review_type_positive float,\n",
    "                         review_type_negative float,\n",
    "                         review_language_mine float,\n",
    "                         Title_listings text COLLATE utf8mb4_unicode_ci,\n",
    "                         Genre varchar(150),\n",
    "                         Release_Date_listings varchar(20),\n",
    "                         Early_Access_Release_Date varchar(20),\n",
    "                         Developer varchar(150) COLLATE utf8mb4_unicode_ci,\n",
    "                         Publisher varchar(150) COLLATE utf8mb4_unicode_ci,\n",
    "                         Franchise varchar(150) COLLATE utf8mb4_unicode_ci,\n",
    "                         languages text,\n",
    "                         num_languages float,\n",
    "                         page_num float,\n",
    "                         listing_num float,\n",
    "                         PRIMARY KEY (listing_id)\n",
    "                     ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci\n",
    "                     \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30455ddb-0934-427c-a864-44a2c2d19ae0",
   "metadata": {},
   "source": [
    "<a id=\"create-table-and-append-`dataframe`-to-table\"></a>\n",
    "\n",
    "### 4.3. [Create table and append `DataFrame` to table](#create-table-and-append-`dataframe`-to-table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa68d17-6f8f-41bc-80ce-740b0fd54509",
   "metadata": {},
   "source": [
    "We'll now create and populate the single `listings` table that will hold the processed version of the scraped data and then show the first four rows of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb395928-cd20-4f75-9efd-bbc114c065ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_query = f\"\"\"SELECT * FROM {table_name} LIMIT 4\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f00adf-b7cc-4362-b014-dcb645451144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Flow(\"Create and Populate Listings Table\") as flow:\n",
    "    # Create table in database\n",
    "    create_table_output = run_sql_query(conn_dict, create_table_query, ssl_cert_path)\n",
    "\n",
    "    # Extract raw listings and search results and Transform\n",
    "    proc_data_output = extract_transform(\n",
    "        fpaths_selenium,\n",
    "        selenium_search_results_pages,\n",
    "        # upstream_tasks=[create_table_output],\n",
    "    )\n",
    "\n",
    "    # Load transformed data into database table\n",
    "    loaded_output = load_my_data(\n",
    "        proc_data_output, table_name, db_connection,\n",
    "        upstream_tasks=[create_table_output, proc_data_output],\n",
    "    )\n",
    "\n",
    "    # Query database\n",
    "    query_output = query_database(\n",
    "        conn_dict,\n",
    "        fetch_query,\n",
    "        table_name,\n",
    "        ssl_cert_path,\n",
    "        upstream_tasks=[loaded_output]\n",
    "    )\n",
    "\n",
    "\n",
    "state_query = flow.run()\n",
    "query_output = state_query.result[query_output].result\n",
    "display(query_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c6e41-6d57-4636-9e19-62f0b4bfeae0",
   "metadata": {},
   "source": [
    "<a id=\"change-column-datatypes\"></a>\n",
    "\n",
    "### 4.4. [Change column datatypes](#change-column-datatypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7baa61a-a3a3-4083-8e13-4c03b805d50c",
   "metadata": {},
   "source": [
    "We'll now change the column datatypes to `INT` for a subset of the non-string columns that we identified earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00cc8f-9077-491b-a100-43e8d70ac32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Flow(\"Update Listings Table Datatypes\") as flow:\n",
    "    # Change column datatype in table\n",
    "    alter_table_output = run_sql_query.map(\n",
    "        query=cn_queries,\n",
    "        conn_dict=unmapped(conn_dict),\n",
    "        ssl_cert_path=unmapped(ssl_cert_path),\n",
    "    )\n",
    "\n",
    "    # Query database\n",
    "    query_output = query_database(\n",
    "        conn_dict,\n",
    "        fetch_query,\n",
    "        table_name,\n",
    "        ssl_cert_path,\n",
    "        upstream_tasks=[alter_table_output]\n",
    "    )\n",
    "\n",
    "\n",
    "state_query = flow.run()\n",
    "query_output = state_query.result[query_output].result\n",
    "display(query_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6296db7-2f8d-40c1-b6d9-aeca157eaf32",
   "metadata": {},
   "source": [
    "Finally, we'll show the datatypes of the table columns that were changed from `float`s to `int`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476f39d-7e93-42ad-b8f2-77e99680dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "col_dtype_query = f\"\"\"\n",
    "                  SELECT column_name,\n",
    "                         data_type\n",
    "                  FROM information_schema.columns\n",
    "                  WHERE table_schema = '{database_name}'\n",
    "                  AND table_name = '{table_name}'\n",
    "                  \"\"\"\n",
    "col_dtypes_changed = list(col_dtypes_to_change_dict)\n",
    "df_col_dtypes = sqlalchemy_show_query_df(col_dtype_query, db_connection, True, False).query(\n",
    "    \"COLUMN_NAME in @col_dtypes_changed\"\n",
    ")\n",
    "display(df_col_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55781a58-0af4-4c58-91cc-75b9483dba32",
   "metadata": {},
   "source": [
    "<a id=\"drop-tables\"></a>\n",
    "\n",
    "## 5. [Drop Tables](#drop-tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0120e76-8f4c-4fe1-aafd-1797efca37d8",
   "metadata": {},
   "source": [
    "Drop table from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff48f0f4-86ea-4384-b604-fe27ef7806c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table_query = f\"\"\"DROP TABLE IF EXISTS {table_name}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db8b78-dbca-48b6-ac88-f727f1b22433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with Flow(\"Delete Listings Table\") as flow:\n",
    "    # Delete table\n",
    "    drop_table_output = run_sql_query(conn_dict, drop_table_query, ssl_cert_path)\n",
    "\n",
    "if drop_table:\n",
    "    state_query = flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591fb068-a434-482d-843b-59be2d2b5b53",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92246953-8d66-4168-a61e-7f81794b903d",
   "metadata": {},
   "source": [
    "<span style=\"float:left\">\n",
    "    <a href=\"./9_download_cloud.ipynb\"><< 9 - Download all scraped data (with requests and selenium) from cloud storage</a>\n",
    "</span>\n",
    "\n",
    "<span style=\"float:right\">\n",
    "    2021 | <a href=\"https://github.com/elsdes3/web-scraping\">@elsdes3</a> (MIT)\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
